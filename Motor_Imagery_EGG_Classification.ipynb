{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPCSlDJfdcGl",
        "outputId": "34f2792a-bc6d-47a0-b5d0-e1cc779881cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Not setting metadata\n",
            "165 matching events found\n",
            "No baseline correction applied\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 0.00076 (2.2e-16 eps * 64 dim * 5.3e+10  max singular value)\n",
            "    Estimated rank (data): 64\n",
            "    data: rank 64 computed from 64 data channels with 0 projectors\n",
            "Reducing data rank from 64 -> 64\n",
            "Estimating class=0 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Estimating class=1 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 0.00076 (2.2e-16 eps * 64 dim * 5.3e+10  max singular value)\n",
            "    Estimated rank (data): 64\n",
            "    data: rank 64 computed from 64 data channels with 0 projectors\n",
            "Reducing data rank from 64 -> 64\n",
            "Estimating class=0 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Estimating class=1 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 0.0008 (2.2e-16 eps * 64 dim * 5.6e+10  max singular value)\n",
            "    Estimated rank (data): 64\n",
            "    data: rank 64 computed from 64 data channels with 0 projectors\n",
            "Reducing data rank from 64 -> 64\n",
            "Estimating class=0 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Estimating class=1 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 0.00074 (2.2e-16 eps * 64 dim * 5.2e+10  max singular value)\n",
            "    Estimated rank (data): 64\n",
            "    data: rank 64 computed from 64 data channels with 0 projectors\n",
            "Reducing data rank from 64 -> 64\n",
            "Estimating class=0 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Estimating class=1 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 0.00074 (2.2e-16 eps * 64 dim * 5.2e+10  max singular value)\n",
            "    Estimated rank (data): 64\n",
            "    data: rank 64 computed from 64 data channels with 0 projectors\n",
            "Reducing data rank from 64 -> 64\n",
            "Estimating class=0 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "Estimating class=1 covariance using LEDOIT_WOLF\n",
            "Done.\n",
            "CSP + LDA Accuracy: 42.42% (+/- 6.36%)\n",
            "Epoch 1, Loss: 10.45, Val Acc: 47.06%\n",
            "Epoch 2, Loss: 10.42, Val Acc: 52.94%\n",
            "Epoch 3, Loss: 10.41, Val Acc: 47.06%\n",
            "Epoch 4, Loss: 10.41, Val Acc: 52.94%\n",
            "Epoch 5, Loss: 10.40, Val Acc: 52.94%\n",
            "Epoch 6, Loss: 10.45, Val Acc: 47.06%\n",
            "Epoch 7, Loss: 10.41, Val Acc: 47.06%\n",
            "Epoch 8, Loss: 10.42, Val Acc: 52.94%\n",
            "Epoch 9, Loss: 10.41, Val Acc: 47.06%\n",
            "Epoch 10, Loss: 10.42, Val Acc: 47.06%\n",
            "Epoch 11, Loss: 10.44, Val Acc: 52.94%\n",
            "Epoch 12, Loss: 10.41, Val Acc: 52.94%\n",
            "Epoch 13, Loss: 10.42, Val Acc: 52.94%\n",
            "Epoch 14, Loss: 10.41, Val Acc: 52.94%\n",
            "Epoch 15, Loss: 10.40, Val Acc: 47.06%\n"
          ]
        }
      ],
      "source": [
        "# EEG Motor Imagery Classification Pipeline\n",
        "# Author: Carlos\n",
        "# Purpose: To demonstrate experience with EEG preprocessing and classification for motor imagery tasks.\n",
        "# Dataset: EEG Motor Movement/Imagery Dataset (PhysioNet: https://physionet.org/content/eegmmidb/1.0.0/)\n",
        "\n",
        "# --- INSTALL DEPENDENCIES ---\n",
        "# Run in Colab or locally to install required libraries\n",
        "!pip install mne torch scikit-learn matplotlib --quiet\n",
        "\n",
        "# --- IMPORT LIBRARIES ---\n",
        "import os\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import mne\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from mne.decoding import CSP\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- PARAMETERS ---\n",
        "subject_ids = list(range(1, 12))  # Subjects 1 to 11\n",
        "recording_id = 8  # Motor imagery task: left and right hand (S###R08.edf)\n",
        "tmin, tmax = 0, 2  # Time window in seconds for epochs\n",
        "\n",
        "# --- DATA LOADING FUNCTION ---\n",
        "def load_and_preprocess(subject_id):\n",
        "    filename = f\"S{subject_id:03d}R{recording_id:02d}.edf\"\n",
        "    url = f\"https://physionet.org/static/published-projects/eegmmidb/1.0.0/S{subject_id:03d}/{filename}\"\n",
        "\n",
        "    if not os.path.exists(filename):\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "    raw = mne.io.read_raw_edf(filename, preload=True, stim_channel='auto', verbose=False)\n",
        "    raw.rename_channels(lambda x: x.strip('.'))\n",
        "    raw.set_montage('standard_1020', on_missing='ignore')\n",
        "    raw.filter(1., 40., fir_design='firwin', verbose=False)\n",
        "\n",
        "    events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
        "    relevant_event_ids = {k: v for k, v in event_id.items() if v in [2, 3]}\n",
        "    if not relevant_event_ids:\n",
        "        return None, None\n",
        "\n",
        "    epochs = mne.Epochs(raw, events, event_id=relevant_event_ids, tmin=tmin, tmax=tmax, baseline=None, preload=True, verbose=False)\n",
        "    epochs.pick_types(eeg=True)  # Keep only EEG channels\n",
        "    labels = epochs.events[:, 2]\n",
        "    return epochs, labels\n",
        "\n",
        "all_epochs = []\n",
        "all_labels = []\n",
        "\n",
        "for sid in subject_ids:\n",
        "    epochs, labels = load_and_preprocess(sid)\n",
        "    if epochs is not None:\n",
        "        all_epochs.append(epochs)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "if not all_epochs:\n",
        "    raise RuntimeError(\"No valid data loaded.\")\n",
        "\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
        "    epochs = mne.concatenate_epochs(all_epochs)\n",
        "\n",
        "y = np.concatenate(all_labels)\n",
        "y_bin = (y == 3).astype(int)\n",
        "X = epochs.get_data().astype(np.float64)\n",
        "\n",
        "# CSP + LDA pipeline\n",
        "csp = CSP(n_components=4, reg='ledoit_wolf', log=True, norm_trace=False)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "clf = Pipeline([('CSP', csp), ('LDA', lda)])\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(clf, X, y_bin, cv=cv, n_jobs=1)\n",
        "print(f\"CSP + LDA Accuracy: {np.mean(scores)*100:.2f}% (+/- {np.std(scores)*100:.2f}%)\")\n",
        "\n",
        "# Prepare data for RNN\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_bin, dtype=torch.long)\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "train_dl = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=10)\n",
        "\n",
        "class EEG_RNN(nn.Module):\n",
        "    def __init__(self, input_size=64, hidden_size=64, num_layers=2, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (B, C, T) -> (B, T, C)\n",
        "        out, _ = self.rnn(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "model = EEG_RNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_dl:\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_dl:\n",
        "            pred = model(xb)\n",
        "            correct += (pred.argmax(1) == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.2f}, Val Acc: {acc:.2f}%\")"
      ]
    }
  ]
}